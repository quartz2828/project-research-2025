# predict_emoji.py
# å®Œæˆç‰ˆã€streamlitã¨ç”¨æ„ã—ãŸè¤‡æ•°ã®å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ–ãƒ©ã‚¦ã‚¶ã«
# å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« ã‹ã‚‰äºˆæ¸¬ã—çµµæ–‡å­—ã‚’å‡ºåŠ›
# ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ãŸå ´æ‰€ã«å¿œã˜ã¦ã€MODEL_DICTã®ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
# å®Ÿè¡Œ streamlit run predict_emoji.py

import streamlit as st
import pandas as pd
import numpy as np
import os, time, signal, torch, joblib
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from st_keyup import st_keyup

# ---- è¨­å®š ----
MODEL_DIR = "results_models/emoji48_0105_w_model_result/final"

# ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
MODEL_DICT = {
    "ãƒ¢ãƒ‡ãƒ«A (Emo48)": "results_models/emoji48_0105_model_result/final",
    "ãƒ¢ãƒ‡ãƒ«A (Emo48 Weighted)": "results_models/emoji48_0105_w_model_result/final",
    "ãƒ¢ãƒ‡ãƒ«B (Emo8)": "results_models/emoji8_model_result/final",
    "ãƒ¢ãƒ‡ãƒ«B (Emo8 Weighted)": "results_models/emoji8_0105_w_model_result/final",
    "ãƒ¢ãƒ‡ãƒ«B (Emo8 Balanced)": "results_models/emoji8_0105_b_model_result/final",

    # "è¡¨ç¤ºå": "ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹",
}

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é¸æŠã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆè¾æ›¸ã®ã‚­ãƒ¼ï¼‰
DEFAULT_MODEL_NAME = list(MODEL_DICT.keys())[0]

# --- çµ‚äº†å‡¦ç† ---
if "exit_app" in st.session_state and st.session_state.exit_app:
    st.empty()
    st.sidebar.empty()
    st.markdown("""
        <div style='text-align: center; margin-top: 100px;'>
            <h1>çµ‚äº†ã—ã¾ã—ãŸ ğŸ‘‹</h1>
            <p>ã“ã®ã‚¿ãƒ–ã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚</p>
        </div>
    """, unsafe_allow_html=True)
    time.sleep(2)
    os.kill(os.getpid(), signal.SIGINT)
    st.stop()

# --- 1. ãƒªã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource(max_entries=2)
def load_prediction_resources(model_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    model.to(device)
    model.eval()
    le = joblib.load(os.path.join(model_dir, "label_encoder.pkl"))
    emoji_labels = le.classes_
    return tokenizer, model, device, emoji_labels

# --- 2. äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ ---
def get_prediction(text, k=5):
    if not text.strip():
        return None, None
    enc = tokenizer([text], truncation=True, padding=True, return_tensors="pt", max_length=128)
    enc = {k: v.to(device) for k, v in enc.items()}
    with torch.no_grad():
        outputs = model(**enc)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()[0]
    top_indices = np.argsort(probs)[::-1][:k]
    return top_indices, probs[top_indices]

# --- 3. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "accumulated_text" not in st.session_state:
    st.session_state.accumulated_text = ""
if "manual_preds" not in st.session_state:
    st.session_state.manual_preds = None
if "reset_counter" not in st.session_state:
    st.session_state.reset_counter = 0

# --- 4. UI/ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.title("çµµæ–‡å­—äºˆæ¸¬ãã‚“")

with st.sidebar:
    st.header("è¨­å®š")
    #ã€€ãƒ¢ãƒ‡ãƒ«
    selected_model_name = st.selectbox("ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«(cache:2models)", list(MODEL_DICT.keys()))
    current_model_path = MODEL_DICT[selected_model_name]
    st.divider() 

    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    is_live_mode = st.toggle("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆè‡ªå‹•ï¼‰", value=True)
    top_k_val = st.slider("æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã®å€™è£œæ•°", 1, 48, 5)
    st.divider()

    # æ–‡ç« æ¶ˆå»
    if st.button("æ–‡ç« ã‚’ãƒªã‚»ãƒƒãƒˆ", type="primary"):
        st.session_state.accumulated_text = ""
        st.session_state.manual_preds = None
        st.rerun()

tokenizer, model, device, emoji_labels = load_prediction_resources(current_model_path)

# --- 5. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
col_input, col_action = st.columns([3, 1])

with col_input:
    if is_live_mode:
        current_input = st_keyup(
            "æ–‡ç« ã‚’å…¥åŠ›:", 
            placeholder="å…¥åŠ›ã™ã‚‹ã¨è‡ªå‹•äºˆæ¸¬...", 
            key=f"live_input_{st.session_state.reset_counter}",
            debounce=400
        )
    else:
        current_input = st.text_input(
            "æ–‡ç« ã‚’å…¥åŠ›:", 
            placeholder="å…¥åŠ›ã—ã¦ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„", 
            key=f"static_input_{st.session_state.reset_counter}"
        )

# --- 6. ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®äºˆæ¸¬å‡¦ç† ---

# A. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ¼ãƒ‰ï¼ˆTop-1ã‚’æ¨ªã«å‡ºã—ã¦æ±ºå®šï¼‰
if is_live_mode and current_input:
    indices, scores = get_prediction(current_input, k=1)
    if indices is not None:
        best_emoji = emoji_labels[indices[0]]
        with col_action:
            st.markdown(f"<h1 style='font-size: 60px; margin: 0;'>{best_emoji}</h1>", unsafe_allow_html=True)
        if st.button("æ±ºå®š â”", type="primary"):
            st.session_state.accumulated_text += f" {current_input}{best_emoji}"
            st.session_state.reset_counter += 1
            st.rerun()

# B. æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨Top-Kã‚’ä¸¦ã¹ã‚‹ï¼‰
elif not is_live_mode:
    if current_input:
        indices, scores = get_prediction(current_input, k=top_k_val)
        st.session_state.manual_preds = (indices, scores)

    # äºˆæ¸¬çµæœè¡¨ç¤º
    if st.session_state.manual_preds and current_input:
        indices, scores = st.session_state.manual_preds
        
        st.write("--- å€™è£œ ---")

        cols = st.columns(len(indices))
        for i, idx in enumerate(indices):
            emoji = emoji_labels[idx]
            prob = scores[i]
            
            # çµµæ–‡å­—ãƒœã‚¿ãƒ³
            if cols[i].button(f"{emoji}\n{prob:.1%}", key=f"btn_{idx}"):
                st.session_state.accumulated_text += f" {current_input}{emoji}"
                
                st.session_state.manual_preds = None
                st.session_state.reset_counter += 1  
                st.rerun()

# æ–‡ç« å…¨ä½“ã®å±¥æ­´ã‚’è¡¨ç¤º
if st.session_state.accumulated_text:
    st.caption(f"**æ–‡ç« ï¼š**")
    st.code(st.session_state.accumulated_text, language=None, wrap_lines=True)

# --- 7. ç®¡ç†æ©Ÿèƒ½ ---
if st.button("çµ‚äº†"):
    st.session_state.exit_app = True
    st.rerun()

st.divider()
st.caption(f" Model: `{selected_model_name}` | âš¡ Device: {device} ")