# plot_confusion_topk.py
# eval_compare_models.py ã§ç”Ÿæˆã•ã‚ŒãŸ predictions_final.csv ã‚’èª­ã¿è¾¼ã¿ã€çœŸãƒ©ãƒ™ãƒ«ã¨äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰(topkç‰ˆã€k=5ã§ä½¿ç”¨)
# ã•ã‚‰ã«ã€æ··åŒè¡Œåˆ—ã‚’æç”»ã—ã¦ã€ã©ã®ã‚¯ãƒ©ã‚¹ãŒã©ã®ã‚¯ãƒ©ã‚¹ã¨æ··åŒã•ã‚Œã‚„ã™ã„ã‹ã‚’è¦–è¦šçš„ã«ç¢ºèªã§ãã‚‹ã‚ˆã†ã«

import os
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================
# è¨­å®š
# ==========================================
INPUT_RESULT = "emo8_0105_B"
INPUT_CSV = f"eval_results/{INPUT_RESULT}/predictions_final.csv"
OUT_DIR = f"eval_results/{INPUT_RESULT}"
FIG_PREFIX = "confmat_top5"

# è©•ä¾¡ã—ãŸã„Kã®å€¤ï¼ˆCSVã®åˆ—ãŒãã‚Œä»¥ä¸ŠæŒã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
K = 5

# è¡¨ç¤ºã™ã‚‹ã‚¯ãƒ©ã‚¹æ•°ï¼ˆNoneãªã‚‰å…¨ã‚¯ãƒ©ã‚¹ï¼‰
TOP_N_CLASSES = None

os.makedirs(OUT_DIR, exist_ok=True)

# ==========================================
# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
# ==========================================
print(f"Loading {INPUT_CSV} ...")
df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False)

# Testãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
df['Train/Dev/Test'] = df['Train/Dev/Test'].astype(str).str.strip()
df_eval = df[df['Train/Dev/Test'].str.lower() == 'test'].copy()
print(f"Test rows: {len(df_eval)}")

# å¿…è¦ãªåˆ—ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
df_eval['best_emoji'] = df_eval['best_emoji'].str.strip()
df_eval['pred_top_k_emojis'] = df_eval['pred_top_k_emojis'].str.strip()

# ç©ºãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
df_eval = df_eval[
    (df_eval['best_emoji'] != '') & 
    (df_eval['pred_top_k_emojis'] != '')
].copy()
print(f"Valid rows: {len(df_eval)}")

# ==========================================
# ãƒ©ãƒ™ãƒ«ã®å®šç¾©ã¨è¡Œåˆ—ã®ä½œæˆ
# ==========================================

# 1. å…¨ã¦ã®æ­£è§£ãƒ©ãƒ™ãƒ«ã¨ã€Top-Kã«å«ã¾ã‚Œã‚‹å…¨ã¦ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’åé›†ã—ã¦ãƒ¦ãƒ‹ã‚ªãƒ³ã‚’ã¨ã‚‹
#    (è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€ã¾ãšã¯æ­£è§£ãƒ©ãƒ™ãƒ«ã®é »åº¦ä¸Šä½ã«çµã‚‹ã‹æ±ºå®šã™ã‚‹)

# æ­£è§£ãƒ©ãƒ™ãƒ«ã®é »åº¦è¨ˆç®—
label_counts = df_eval['best_emoji'].value_counts()
all_true_labels = label_counts.index.tolist()

if TOP_N_CLASSES is not None:
    # é »åº¦ä¸Šä½Nä»¶ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹
    target_labels = all_true_labels[:TOP_N_CLASSES]
else:
    target_labels = all_true_labels

print(f"Target labels count: {len(target_labels)}")
print("Labels:", target_labels)

# ãƒ©ãƒ™ãƒ« â†’ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¾æ›¸
label_to_idx = {label: i for i, label in enumerate(target_labels)}
n_labels = len(target_labels)

# 2. Top-K æ··åŒè¡Œåˆ—ã®åˆæœŸåŒ– (ã‚¼ãƒ­è¡Œåˆ—)
# è¡Œ: æ­£è§£ãƒ©ãƒ™ãƒ« (True)
# åˆ—: äºˆæ¸¬ãƒ©ãƒ™ãƒ« (Predicted in Top-K)
cm_accumulated = np.zeros((n_labels, n_labels), dtype=int)

# 3. é›†è¨ˆãƒ«ãƒ¼ãƒ—
#    sklearnã®confusion_matrixã¯1å¯¾1å°‚ç”¨ãªã®ã§ã€æ‰‹å‹•ã§é›†è¨ˆã—ã¾ã™
count_included = 0 # ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚ŒãŸæ•°

for _, row in df_eval.iterrows():
    true_label = row['best_emoji']
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤–ã®æ­£è§£ãƒ©ãƒ™ãƒ«ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
    if true_label not in label_to_idx:
        continue
    
    true_idx = label_to_idx[true_label]
    count_included += 1
    
    # æ–‡å­—åˆ— "ğŸ˜‰,ğŸ˜¨,ğŸ˜­..." ã‚’ãƒªã‚¹ãƒˆã«åˆ†è§£
    # CSVã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã£ã¦ã¯å¼•ç”¨ç¬¦ãªã©ãŒæ®‹ã‚‹å ´åˆãŒã‚ã‚‹ã®ã§æ³¨æ„ã—ã¦split
    preds_str = row['pred_top_k_emojis']
    # ã‚«ãƒ³ãƒã§åˆ†å‰²ã—ã€ç©ºç™½é™¤å»ã€‚Kå€‹ã¾ã§å–å¾—
    pred_list = [p.strip() for p in preds_str.split(',') if p.strip()][:K]
    
    # Top-Kå€‹ã®äºˆæ¸¬ãã‚Œãã‚Œã«ã¤ã„ã¦ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—
    for p_label in pred_list:
        if p_label in label_to_idx:
            pred_idx = label_to_idx[p_label]
            cm_accumulated[true_idx, pred_idx] += 1

print(f"Aggregated {count_included} samples into Top-{K} Matrix.")

# ==========================================
# æ­£è¦åŒ– (Normalization)
# ==========================================
# è¡Œã”ã¨ã®åˆè¨ˆï¼ˆãã®æ­£è§£ãƒ©ãƒ™ãƒ«ã®å‡ºç¾å›æ•°ï¼‰ã§å‰²ã‚‹
# æ³¨æ„: Top-Kãªã®ã§ã€è¡Œã®åˆè¨ˆå€¤ã¯ã€Œã‚µãƒ³ãƒ—ãƒ«æ•° Ã— Kã€ã«ãªã‚Šã¾ã›ã‚“ã€‚
# ã€Œã‚µãƒ³ãƒ—ãƒ«æ•°ã€ã§å‰²ã‚‹ã“ã¨ã§ã€ç¢ºç‡ã¯ä»¥ä¸‹ã®æ„å‘³ã«ãªã‚Šã¾ã™ã€‚
# å¯¾è§’æˆåˆ† (i, i) => æ­£è§£ãƒ©ãƒ™ãƒ«iãŒTop-Kã«å«ã¾ã‚ŒãŸç¢ºç‡ (Recall@K)
# éå¯¾è§’æˆåˆ†(i, j) => æ­£è§£ãŒiã®ã¨ãã€èª¤ã£ã¦jãŒTop-Kã«å…¥ã£ã¦ããŸç¢ºç‡

# å„æ­£è§£ãƒ©ãƒ™ãƒ«ã®å®Ÿéš›ã®å‡ºç¾å›æ•°ï¼ˆsupportï¼‰ã‚’è¨ˆç®—
# df_evalã®ä¸­ã§ã€target_labelsã«å«ã¾ã‚Œã‚‹ã‚‚ã®ã ã‘å†é›†è¨ˆ
support = np.zeros(n_labels)
for i, label in enumerate(target_labels):
    support[i] = len(df_eval[df_eval['best_emoji'] == label])

# ã‚¼ãƒ­é™¤ç®—å›é¿
support[support == 0] = 1 
# shapeã‚’(N, 1)ã«ã—ã¦ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
cm_norm = cm_accumulated.astype('float') / support[:, None]

# ==========================================
# ãƒ—ãƒ­ãƒƒãƒˆ
# ==========================================
plt.rcParams.update({'font.size': 10})
# ã‚¯ãƒ©ã‚¹æ•°ã«å¿œã˜ã¦ã‚µã‚¤ã‚ºè‡ªå‹•èª¿æ•´
figsize = (max(10, n_labels * 0.8), max(8, n_labels * 0.6))

plt.figure(figsize=figsize)
sns.heatmap(
    cm_norm, 
    annot=True, 
    fmt='.2f', 
    xticklabels=target_labels, 
    yticklabels=target_labels, 
    cmap='Blues',
    vmin=0, vmax=1.0  # ç¢ºç‡ã¯0~1ã®ç¯„å›²
)
plt.xlabel(f'Predicted in Top-{K}')
plt.ylabel('True label')
plt.title(f'Top-{K} Accumulated Confusion Matrix (Normalized by Support)\nDiagonal represents Recall@{K}')
plt.tight_layout()

out_path = os.path.join(OUT_DIR, f"{FIG_PREFIX}_norm.png")
plt.savefig(out_path, dpi=200)
plt.close()

print(f"Saved figure to: {out_path}")

# ==========================================
# ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ: ã‚¯ãƒ©ã‚¹ã”ã¨ã®Recall@K
# ==========================================
report_path = os.path.join(OUT_DIR, f"{FIG_PREFIX}_report.txt")
with open(report_path, "w", encoding="utf-8") as f:
    f.write(f"Class-wise Recall@{K} (Probability that True Label is in Top-{K})\n")
    f.write("-" * 50 + "\n")
    for i, label in enumerate(target_labels):
        recall_at_k = cm_norm[i, i]
        count = int(support[i])
        f.write(f"{label} : {recall_at_k:.4f} (n={count})\n")

print(f"Saved report to: {report_path}")