# predict_emoji_manual.py
# ãƒ†ã‚¹ãƒˆç”¨ã€streamlitã¨ç”¨æ„ã—ãŸå­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã«å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« ã‹ã‚‰äºˆæ¸¬ã—çµµæ–‡å­—ã‚’å‡ºåŠ›
# å®Ÿè¡Œ streamlit run predict_emoji_manual.py

import streamlit as st
import pandas as pd
import numpy as np
import os, time, signal
import torch
import joblib
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ---- è¨­å®š ----
MODEL_DIR = "results_models/emoji48_0105_w_model_result/final"
# è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã® TOP_K ã«åˆã‚ã›ã‚‹
DEFAULT_TOP_K = 5 

# --- 1. ãƒªã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_prediction_resources():
    # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # A. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    if not os.path.exists(MODEL_DIR):
        st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MODEL_DIR}")
        st.stop()

    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
    model.to(device)
    model.eval()
    
    # B. ãƒ©ãƒ™ãƒ«æƒ…å ±ã®ãƒ­ãƒ¼ãƒ‰ (æ‰‹å‹•ã§ç”¨æ„ã—ãŸ label_encoder.pkl ã‚’ä½¿ç”¨)
    le_path = os.path.join(MODEL_DIR, "label_encoder.pkl")
    if os.path.exists(le_path):
        le = joblib.load(le_path)
        emoji_labels = le.classes_
    else:
        st.error(f"ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {le_path}")
        st.stop()
    
    return tokenizer, model, device, emoji_labels

# ãƒªã‚½ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ãƒ‰
tokenizer, model, device, emoji_labels = load_prediction_resources()

# --- 2. UIéƒ¨åˆ† ---
st.title("âœ¨çµµæ–‡å­—äºˆæ¸¬")
st.write(f"ãƒ¢ãƒ‡ãƒ«: `{os.path.basename(os.path.dirname(MODEL_DIR))}`")

# å€™è£œæ•°ã®è¨­å®š
top_k = st.slider("è¡¨ç¤ºã™ã‚‹å€™è£œæ•° (Top-K)", 1, len(emoji_labels), DEFAULT_TOP_K)

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
user_input = st.text_area("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä»Šæ—¥ã‹ã‚‰é•·æœŸä¼‘æš‡ã ããƒ¼ãƒ¼ãƒ¼ï¼ï¼ï¼", height=100)

# --- 3. äºˆæ¸¬å®Ÿè¡Œ (eval_compare_models.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»æ¤) ---
if st.button("äºˆæ¸¬å®Ÿè¡Œ"):
    if user_input.strip() == "":
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("æ¨è«–ä¸­..."):
            # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã® predict_with_model å†…ã®å‡¦ç†ã‚’1ä»¶ç”¨ã«é©ç”¨
            enc = tokenizer([user_input], truncation=True, padding=True, return_tensors="pt", max_length=128)
            enc = {k: v.to(device) for k, v in enc.items()}
            
            with torch.no_grad():
                outputs = model(**enc)
                logits = outputs.logits
                # Softmaxã§ç¢ºç‡ç®—å‡º
                probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0]
            
            # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ã‚½ãƒ¼ãƒˆé † (é™é †ã§ä¸Šä½Kå€‹)
            top_indices = np.argsort(probs)[::-1][:top_k]
            top_probs = probs[top_indices]

            # --- çµæœè¡¨ç¤º ---
            st.subheader("ğŸ”® äºˆæ¸¬çµæœ")
            
            # æœ€ä¸Šä½ã®è¡¨ç¤º
            best_emoji = emoji_labels[top_indices[0]]
            st.markdown(f"<div style='text-align: center; font-size: 80px; margin: 20px;'>{best_emoji}</div>", unsafe_allow_html=True)
            st.metric(label="Top-1 äºˆæ¸¬", value=best_emoji, delta=f"ä¿¡é ¼åº¦: {top_probs[0]:.2%}")

            # Top-K ä¸€è¦§
            st.write(f"Top-{top_k} å€™è£œ:")
            res_df = pd.DataFrame({
                "çµµæ–‡å­—": [emoji_labels[i] for i in top_indices],
                "ç¢ºç‡": [f"{p:.4%}" for p in top_probs]
            })
            st.table(res_df)

# --- 4. çµ‚äº†ãƒ»ç®¡ç† ---
st.divider()
st.caption(f"Device: {device} | Labels: {len(emoji_labels)} classes")

if st.button("çµ‚äº†"):
    st.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚")
    time.sleep(1)
    os.kill(os.getpid(), signal.SIGINT)
    os._exit(0)