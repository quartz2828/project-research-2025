# inference.py
# ãƒ†ã‚¹ãƒˆç”¨ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ–‡ç« ã‹ã‚‰çµµæ–‡å­—ã‚’äºˆæ¸¬ã™ã‚‹

import os
import torch
import pandas as pd
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.preprocessing import LabelEncoder

# ---------------------------------------------------------
# 1. è¨­å®šã¨æº–å‚™
# ---------------------------------------------------------
# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
#MODEL_PATH = "final_emoji_model" # train_emoji.pyã§ä¿å­˜ã—ãŸãƒ•ã‚©ãƒ«ãƒ€å
MODEL_PATH = os.path.join('results_models', 'emoji8_0105_w_model_result', 'final')

DATA_PATH = os.path.join('data', 'wrime_emotag8_WR.csv')

# GPUè¨­å®š
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ---------------------------------------------------------
# 2. ãƒ©ãƒ™ãƒ«æƒ…å ±ã®å¾©å…ƒ
# ---------------------------------------------------------
# ãƒ¢ãƒ‡ãƒ«ã¯ã€Œæ•°å­—(0, 1, 2...)ã€ã§äºˆæ¸¬ã™ã‚‹ã®ã§ã€ãã‚Œã‚’ã€Œçµµæ–‡å­—ã€ã«æˆ»ã™ãŸã‚ã®è¾æ›¸ãŒå¿…è¦ã§ã™ã€‚
# å­¦ç¿’æ™‚ã¨åŒã˜æ‰‹é †ã§ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DATA_PATH}")

df = pd.read_csv(DATA_PATH)
le = LabelEncoder()
le.fit(df['best_emoji'])
emoji_labels = le.classes_

print("ãƒ©ãƒ™ãƒ«æƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

# ---------------------------------------------------------
# 3. ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®èª­ã¿è¾¼ã¿
# ---------------------------------------------------------
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MODEL_PATH}\nå…ˆã« train_emoji.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

print("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
# ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã‚€
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.to(device)
model.eval()
print("æº–å‚™å®Œäº†ï¼")

# ---------------------------------------------------------
# 4. äºˆæ¸¬é–¢æ•°
# ---------------------------------------------------------
def generate_emoji(text, top_k=8):
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=128)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # æ¨è«–
    with torch.no_grad():
        outputs = model(**inputs)
    
    # ç¢ºç‡è¨ˆç®—
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].cpu().numpy()
    
    # ä¸Šä½Kå€‹ã‚’å–å¾—
    top_indices = probs.argsort()[-top_k:][::-1]
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“ å…¥åŠ›: {text}")
    print("---------------------------------")
    
    results = []
    for i in top_indices:
        emoji = emoji_labels[i]
        score = probs[i]
        print(f"{emoji}  (ç¢ºç‡: {score:.1%})")
        results.append(emoji)
        
    return results[0] # æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„çµµæ–‡å­—ã‚’è¿”ã™

# ---------------------------------------------------------
# 5. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
# ---------------------------------------------------------
if __name__ == "__main__":
    print("\n" + "="*40)
    print("  âœ¨ çµµæ–‡å­—ç”ŸæˆAI (çµ‚äº†ã™ã‚‹ã«ã¯ 'q' ã‚’å…¥åŠ›) âœ¨")
    print("="*40 + "\n")

    while True:
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘
            input_text = input("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
            
            if input_text.lower() in ['q', 'exit', 'quit']:
                print("çµ‚äº†ã—ã¾ã™ã€‚")
                break
            
            if not input_text.strip():
                continue

            # ç”Ÿæˆå®Ÿè¡Œ
            generate_emoji(input_text)
            
        except KeyboardInterrupt:
            print("\nçµ‚äº†ã—ã¾ã™ã€‚")
            break
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")